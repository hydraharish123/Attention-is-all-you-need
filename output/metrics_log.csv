Model,Attention,Accuracy,F1,Precision,Recall,Loss
RNN,NoAttention,0.4882,0.328,0.2441,0.4998,0.6977
RNN,Bahdanau,0.8638,0.8638,0.864,0.8641,0.324
RNN,Dot,0.4882,0.328,0.2441,0.4998,0.6958
RNN,General,0.8545,0.8544,0.8568,0.8555,0.3437
RNN,Concat,0.852,0.851,0.8577,0.8505,0.3525
LSTM,NoAttention,0.5118,0.3389,0.7559,0.5002,0.6929
LSTM,Bahdanau,0.8843,0.8842,0.8844,0.8841,0.2844
LSTM,Dot,0.874,0.8739,0.8739,0.874,0.3005
LSTM,General,0.5117,0.3385,0.2558,0.5,0.6928
LSTM,Concat,0.8807,0.8806,0.8835,0.8817,0.2897
BiRNN,NoAttention,0.5138,0.3481,0.5786,0.5023,0.7113
BiRNN,Bahdanau,0.8668,0.8667,0.8668,0.8667,0.313
BiRNN,Dot,0.5295,0.5289,0.5308,0.5306,0.6867
BiRNN,General,0.7285,0.7282,0.7284,0.7281,0.563
BiRNN,Concat,0.851,0.8504,0.8614,0.853,0.3619
BiLSTM,NoAttention,0.8428,0.8427,0.8428,0.8427,0.3746
BiLSTM,Bahdanau,0.8792,0.8792,0.8804,0.8799,0.3082
BiLSTM,Dot,0.8727,0.8721,0.8758,0.8716,0.3051
BiLSTM,General,0.8843,0.8843,0.8843,0.8842,0.3116
BiLSTM,Concat,0.8855,0.8854,0.8859,0.8851,0.2777
